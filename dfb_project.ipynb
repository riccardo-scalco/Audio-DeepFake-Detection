{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":3842332,"datasetId":2286778,"databundleVersionId":3897191}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Digital Forensics and Biometrics Project\nScalco Riccardo (id: 2155352)\\\nFerrari Luca (id: 2166294)","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nimport torchaudio\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchaudio.transforms as T\nimport torchaudio.functional as AF\nimport random\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport IPython.display as ipd\n\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.calibration import calibration_curve\nfrom sklearn.metrics import roc_curve, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_fscore_support, classification_report, confusion_matrix\nimport seaborn as sns\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.amp import GradScaler, autocast\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nRANDOM_STATE=42\nN_SAMPLE_TRAIN=5000\nN_SAMPLE_VAL=4000\nSAMPLE_RATE = 16_000\nEPOCH = 50\nPATIENCE = 5\nN_MELS = 80\nN_LFCC = 60\nPROBABILITY_AUGMENT = 0.3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_ROOT = Path(\"/kaggle/input/asvpoof-2019-dataset\")\n\nAUDIO_DIR_LA = DATA_ROOT / \"LA\" / \"LA\" / \"ASVspoof2019_LA_train\" / \"flac\"\nPROTO_FILE_LA = DATA_ROOT / \"LA\" / \"LA\" / \"ASVspoof2019_LA_cm_protocols\" / \"ASVspoof2019.LA.cm.train.trn.txt\"\n\nAUDIO_DIR_VAL_LA = DATA_ROOT / \"LA\" / \"LA\" / \"ASVspoof2019_LA_dev\" / \"flac\"\nPROTO_FILE_VAL_LA = DATA_ROOT / \"LA\" / \"LA\" / \"ASVspoof2019_LA_cm_protocols\" / \"ASVspoof2019.LA.cm.dev.trl.txt\"\n\nAUDIO_DIR_TEST_LA = DATA_ROOT / \"LA\" / \"LA\" / \"ASVspoof2019_LA_eval\" / \"flac\"\nPROTO_FILE_TEST_LA = DATA_ROOT / \"LA\" / \"LA\" / \"ASVspoof2019_LA_cm_protocols\" / \"ASVspoof2019.LA.cm.eval.trl.txt\"\n\nAUDIO_DIR_PA = DATA_ROOT / \"PA\" / \"PA\" / \"ASVspoof2019_PA_train\" / \"flac\"\nPROTO_FILE_PA = DATA_ROOT / \"PA\" / \"PA\" / \"ASVspoof2019_PA_cm_protocols\" / \"ASVspoof2019.PA.cm.train.trn.txt\"\n\nAUDIO_DIR_VAL_PA = DATA_ROOT / \"PA\" / \"PA\" / \"ASVspoof2019_PA_dev\" / \"flac\"\nPROTO_FILE_VAL_PA = DATA_ROOT / \"PA\" / \"PA\" / \"ASVspoof2019_PA_cm_protocols\" / \"ASVspoof2019.PA.cm.dev.trl.txt\"\n\nAUDIO_DIR_TEST_PA = DATA_ROOT / \"PA\" / \"PA\" / \"ASVspoof2019_PA_eval\" / \"flac\"\nPROTO_FILE_TEST_PA = DATA_ROOT / \"PA\" / \"PA\" / \"ASVspoof2019_PA_cm_protocols\" / \"ASVspoof2019.PA.cm.eval.trl.txt\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_proto_file(proto_file, audio_dir, audio_ext, tag):\n    rows = []\n    with open(proto_file, 'r') as f:\n        for line in f:\n            parts = line.strip().split()\n            speaker_id = parts[0]\n            audio_file_name = parts[1]\n            environment_id = parts[2]\n            attack_id = parts[3]\n            label = parts[-1]  # \"spoof\" o \"bonafide\"\n            \n            filepath = audio_dir / f\"{audio_file_name}.{audio_ext}\"\n            rows.append({\n                \"speaker_id\": speaker_id,\n                \"audio_file_name\": audio_file_name,\n                #\"environment_id\": environment_id,\n                #\"attack_id\": attack_id,\n                \"label\": 1 if label == \"spoof\" else 0,\n                \"path\": filepath,\n                \"tag\": tag\n            })\n    return pd.DataFrame(rows)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"la_train = read_proto_file(PROTO_FILE_LA, AUDIO_DIR_LA, \"flac\", \"LA\")\nla_t_1 = la_train[la_train[\"label\"] == 1].sample(n=N_SAMPLE_TRAIN//2, random_state=RANDOM_STATE)\nla_t_0 = la_train[la_train[\"label\"] == 0].sample(n=N_SAMPLE_TRAIN//2, random_state=RANDOM_STATE)\nla_train_reduced = pd.concat([la_t_1, la_t_0], ignore_index=True)\npa_train = read_proto_file(PROTO_FILE_PA, AUDIO_DIR_PA, \"flac\", \"PA\")\npa_t_1 = pa_train[pa_train[\"label\"] == 1].sample(n=N_SAMPLE_TRAIN//2, random_state=RANDOM_STATE)\npa_t_0 = pa_train[pa_train[\"label\"] == 0].sample(n=N_SAMPLE_TRAIN//2, random_state=RANDOM_STATE)\npa_train_reduced = pd.concat([pa_t_1, pa_t_0], ignore_index=True)\ntrain_df = pd.concat([la_train_reduced, pa_train_reduced], ignore_index=True)\n\nla_validation = read_proto_file(PROTO_FILE_VAL_LA, AUDIO_DIR_VAL_LA, \"flac\", \"LA\")\nla_v_1 = la_validation[la_validation[\"label\"] == 1].sample(n=N_SAMPLE_VAL//2, random_state=RANDOM_STATE)\nla_v_0 = la_validation[la_validation[\"label\"] == 0].sample(n=N_SAMPLE_VAL//2, random_state=RANDOM_STATE)\nla_val_reduced = pd.concat([la_v_1, la_v_0], ignore_index=True)\npa_validation = read_proto_file(PROTO_FILE_VAL_PA, AUDIO_DIR_VAL_PA, \"flac\", \"PA\")\npa_v_1 = pa_validation[pa_validation[\"label\"] == 1].sample(n=N_SAMPLE_VAL//2, random_state=RANDOM_STATE)\npa_v_0 = pa_validation[pa_validation[\"label\"] == 0].sample(n=N_SAMPLE_VAL//2, random_state=RANDOM_STATE)\npa_val_reduced = pd.concat([pa_v_1, pa_v_0], ignore_index=True)\nvalidation_df = pd.concat([la_val_reduced, pa_val_reduced], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\ntrain_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\ntrain_df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_df['label'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check for the Augmentation possibility","metadata":{}},{"cell_type":"markdown","source":"The following datasets contain a set of file that will be added to our sample to add some noise or some reverbation ","metadata":{}},{"cell_type":"code","source":"def plot_waveform_and_spectrogram(waveform, sr, title=\"Audio Analysis\"):\n    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n\n    # --- Waveform ---\n    axes[0].plot(waveform[0].numpy())\n    axes[0].set_title(\"Waveform\")\n    axes[0].set_xlabel(\"Samples\")\n    axes[0].set_ylabel(\"Amplitude\")\n\n    # --- Spectrogram ---\n    Pxx, freqs, bins, im = axes[1].specgram(waveform[0].numpy(), Fs=sr)\n    axes[1].set_title(\"Spectrogram\")\n    axes[1].set_xlabel(\"Time (s)\")\n    axes[1].set_ylabel(\"Frequency (Hz)\")\n    \n    fig.colorbar(im, ax=axes[1], label=\"dB\")\n\n    fig.suptitle(title)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_path = train_df.loc[0, 'path']\ntag = train_df.loc[0, 'tag']\nwaveform, sr = torchaudio.load(sample_path)\nprint(\"Sampling rate:\", sr)\nprint(\"Waveform shape:\", waveform.shape)\nplot_waveform_and_spectrogram(waveform, sr, \"Original Audio\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Noise","metadata":{}},{"cell_type":"code","source":"wav = waveform\nnoise = torch.randn_like(wav)\nsnr = random.uniform(15, 30)\nsnr = 10 ** (snr / 20)\nnoise * wav.std() / (snr * noise.std() + 1e-8)\nwav = wav + noise\n\nplot_waveform_and_spectrogram(waveform, sr, \"Original Audio\")\nplot_waveform_and_spectrogram(wav, sr, \"Noisy Audio\")\n\nprint(\"Original:\")\nipd.display(ipd.Audio(waveform.numpy(), rate=sr))\n\nprint(\"Noisy:\")\nipd.display(ipd.Audio(wav.numpy(), rate=sr))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Time-Stretch","metadata":{}},{"cell_type":"code","source":"wav = waveform\nrate = random.uniform(0.9, 1.1)\nlength = int(wav.shape[1] / rate)\nwav = torch.nn.functional.interpolate(\n    wav.unsqueeze(0), size=length, mode=\"linear\", align_corners=False\n).squeeze(0)\n\nplot_waveform_and_spectrogram(waveform, sr, \"Original Audio\")\nplot_waveform_and_spectrogram(wav, sr, \"Time-Stretch Audio\")\n\nprint(\"Original:\")\nipd.display(ipd.Audio(waveform.numpy(), rate=sr))\n\nprint(\"Time-Stretch:\")\nipd.display(ipd.Audio(wav.numpy(), rate=sr))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pitch Shift","metadata":{}},{"cell_type":"code","source":"wav = waveform\nn_steps = random.choice([-1, 1])\nfft = torch.fft.rfft(wav)\nshift = int(n_steps * fft.shape[-1] / 12)  \nfft = torch.roll(fft, shifts=shift, dims=-1)\nwav = torch.fft.irfft(fft, n=wav.shape[-1])\n\nplot_waveform_and_spectrogram(waveform, sr, \"Original Audio\")\nplot_waveform_and_spectrogram(wav, sr, \"Pitch Shift Audio\")\n\nprint(\"Original:\")\nipd.display(ipd.Audio(waveform.numpy(), rate=sr))\n\nprint(\"Pitch Shift:\")\nipd.display(ipd.Audio(wav.numpy(), rate=sr))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Time Mask","metadata":{}},{"cell_type":"code","source":"time_mask_param = int(0.1 * waveform.shape[1]) \nt0 = random.randint(0, waveform.shape[1] - time_mask_param)\nt_len = random.randint(50, time_mask_param)\n\nwav = waveform.clone()\nwav[:, t0:t0+t_len] = 0.0  \n\nplot_waveform_and_spectrogram(waveform, sr, \"Original Audio\")\nplot_waveform_and_spectrogram(wav, sr, \"Audio with Random Time-Mask\")\n\nprint(\"Original:\")\nipd.display(ipd.Audio(waveform.numpy(), rate=sr))\n\nprint(\"Random Time-Mask:\")\nipd.display(ipd.Audio(wav.numpy(), rate=sr))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Frequency Mask","metadata":{}},{"cell_type":"code","source":"wav = waveform[0].unsqueeze(0) \nn_mels = 64\nn_fft = 1024\nhop_length = 256\n\nmel_spectrogram = T.MelSpectrogram(\n    sample_rate=SAMPLE_RATE,\n    n_fft=n_fft,\n    hop_length=hop_length,\n    n_mels=n_mels\n)\nmel_spec = mel_spectrogram(wav)\n\nfreq_mask_param = int(n_mels * 0.2)\nf_start = random.randint(0, n_mels - freq_mask_param)\nmel_spec[:, f_start:f_start+freq_mask_param, :] = 0\ninverse_mel = T.InverseMelScale(n_stft=n_fft//2 + 1, n_mels=n_mels)\nlinear_spec = inverse_mel(mel_spec)\ngriffin_lim = T.GriffinLim(n_fft=n_fft, hop_length=hop_length)\nwav = griffin_lim(linear_spec)\n\nplot_waveform_and_spectrogram(waveform, sr, \"Original Audio\")\nplot_waveform_and_spectrogram(wav, sr, \"Audio with Random Frequency-Mask\")\n\nprint(\"Original:\")\nipd.display(ipd.Audio(waveform.numpy(), rate=sr))\n\nprint(\"Random Frequency-Mask:\")\nipd.display(ipd.Audio(wav.numpy(), rate=sr))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this last case is convenient to plot also the spectrogram before the inverse trasformation, to see clearly where we delete some frequency.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 4))\nplt.imshow(mel_spec[0].log2().numpy(), aspect='auto', origin='lower', cmap='viridis')\nplt.colorbar(format='%+2.0f dB')\nplt.title(\"MelSpectrogram con Frequency Mask\")\nplt.xlabel(\"Time Frames\")\nplt.ylabel(\"Mel Bands\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the Augment class","metadata":{}},{"cell_type":"code","source":"class MelFeatureExtractor:\n    def __init__(self,\n                 target_sr=16000,\n                 n_fft=512,\n                 hop_length=160,\n                 win_length=400,\n                 n_mels=80):\n\n        self.target_sr = target_sr\n        self.n_fft = n_fft\n        self.hop_length = hop_length\n        self.win_length = win_length\n        self.n_mels = n_mels\n\n        self.mel_transform = T.MelSpectrogram(\n            sample_rate=self.target_sr,\n            n_fft=self.n_fft,\n            hop_length=self.hop_length,\n            win_length=self.win_length,\n            n_mels=self.n_mels\n        )\n        self.db_transform = T.AmplitudeToDB()\n\n    def __call__(self, wav: torch.Tensor):\n        mel_spec = self.mel_transform(wav)\n        mel_spec_db = self.db_transform(mel_spec)\n        return mel_spec_db","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Augment(torch.nn.Module):\n    def __init__(self, enable=True, probability=0.2):\n        super().__init__()\n        self.enable = enable\n        self.probability = probability\n        self.mel_representation = MelFeatureExtractor() \n\n    def forward(self, wav: torch.Tensor, tag: str = \"LA\"):\n        if not self.enable:\n            mel_rep = self.mel_representation(wav)\n            return mel_rep\n\n        if tag == \"LA\":\n            if random.random() < self.probability:\n                noise = torch.randn_like(wav)\n                snr = random.uniform(15, 30)\n                wav = wav + self._scale_to_snr(wav, noise, snr)\n\n\n        if random.random() < self.probability:\n            rate = random.uniform(0.9, 1.1)\n            length = int(wav.shape[1] / rate)\n            wav = torch.nn.functional.interpolate(\n                wav.unsqueeze(0), size=length, mode=\"linear\", align_corners=False\n            ).squeeze(0)\n\n        if random.random() < self.probability:\n            n_steps = random.choice([-1, 1])\n            fft = torch.fft.rfft(wav)\n            shift = int(n_steps * fft.shape[-1] / 12) \n            fft = torch.roll(fft, shifts=shift, dims=-1)\n            wav = torch.fft.irfft(fft, n=wav.shape[-1])\n\n        if random.random() < self.probability:\n            time_mask_param = int(0.1 * waveform.shape[1]) \n            t0 = random.randint(0, waveform.shape[1] - time_mask_param)\n            t_len = random.randint(50, time_mask_param)\n            wav = waveform.clone()\n            wav[:, t0:t0+t_len] = 0.0\n\n        mel_rep = self.mel_representation(wav)\n        \n        if random.random() < self.probability:\n            freq_mask_param = int(n_mels * 0.2)\n            f_start = random.randint(0, n_mels - freq_mask_param)\n            mel_rep[:, f_start:f_start+freq_mask_param, :] = 0\n\n        return mel_rep\n\n    @staticmethod\n    def _scale_to_snr(clean, noise, snr_db):\n        snr = 10 ** (snr_db / 20)\n        return noise * clean.std() / (snr * noise.std() + 1e-8)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset & Dataloader","metadata":{}},{"cell_type":"code","source":"class SpoofDataset(Dataset):\n    def __init__(self, df, mel_dir):\n        self.df = df\n        self.mel_dir = mel_dir\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        path = Path(self.mel_dir)\n        path = path / f\"{row['audio_file_name']}.pt\"\n        mel_db = torch.load(path)\n        label = row[\"label\"]\n        return mel_db, torch.tensor(label, dtype=torch.long)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_fn(batch):\n    mels, labels = zip(*batch)\n    max_len = max([mel.shape[-1] for mel in mels])\n    padded_mels = []\n    for mel in mels:\n        pad_len = max_len - mel.shape[-1]\n        padded = torch.nn.functional.pad(mel, (0, pad_len))\n        padded_mels.append(padded)\n    return torch.stack(padded_mels), torch.tensor(labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_mel(df, output_path, augmentation=False, probability_of_augment=0.2):\n    output_dir = Path(output_path)\n    output_dir.mkdir(exist_ok=True, parents=True)\n\n    aug = Augment(enable=augmentation, probability=probability_of_augment)\n\n    for i, row in df.iterrows():\n        path = row['path']\n        waveform, sr = torchaudio.load(path)\n        tag = row['tag']\n        mel_db = aug(waveform, tag)\n\n        save_path = output_dir / f\"{row['audio_file_name']}.pt\"\n        torch.save(mel_db, save_path)\n        \n        if (i+1) % 5000 == 0 or (i+1) == len(df):\n            print(f\"{i+1}/{len(df)} Mel salvati\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_mel(\n    df=train_df, \n    output_path=\"mel_train\", \n    augmentation=True,\n    probability_of_augment=PROBABILITY_AUGMENT\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_mel(\n    df=validation_df, \n    output_path=\"mel_val\", \n    augmentation=False,\n    probability_of_augment=PROBABILITY_AUGMENT\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = SpoofDataset(train_df, \"mel_train\")\nval_dataset = SpoofDataset(validation_df, \"mel_val\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class SEBlock(nn.Module):    \n    def __init__(self, channels, reduction=16):\n        super().__init__()\n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, channels // reduction),\n            nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.global_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResidualSEBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, reduction=16):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.se = SEBlock(out_channels, reduction)\n        \n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        \n        self.dropout = nn.Dropout2d(0.1)\n    \n    def forward(self, x):\n        residual = x\n        \n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.dropout(out)\n        out = self.bn2(self.conv2(out))\n        \n        out = self.se(out)\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        \n        return out","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AttentionPooling(nn.Module):    \n    def __init__(self, in_dim):\n        super().__init__()\n        self.attention = nn.Sequential(\n            nn.Conv2d(in_dim, in_dim // 4, 1),\n            nn.ReLU(),\n            nn.Conv2d(in_dim // 4, 1, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        att_weights = self.attention(x)  \n        \n        weighted_features = x * att_weights\n        pooled = F.adaptive_avg_pool2d(weighted_features, 1)  \n        \n        return pooled.squeeze(-1).squeeze(-1) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SpoofNet(nn.Module):  \n    def __init__(self, input_features=227, num_classes=2, dropout=0.3):\n        super().__init__()\n        \n        self.input_conv = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.layer1 = self._make_layer(64, 128, 2, stride=1)\n        self.layer2 = self._make_layer(128, 256, 2, stride=2)\n        self.layer3 = self._make_layer(256, 512, 2, stride=2)\n        self.layer4 = self._make_layer(512, 512, 2, stride=2)\n        \n        self.attention_pool = AttentionPooling(512)\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(256, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, num_classes)\n        )\n        \n        self._initialize_weights()\n    \n    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n        layers = []\n        layers.append(ResidualSEBlock(in_channels, out_channels, stride))\n        \n        for _ in range(1, num_blocks):\n            layers.append(ResidualSEBlock(out_channels, out_channels))\n        \n        return nn.Sequential(*layers)\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        if x.dim() == 3:\n            x = x.unsqueeze(1) \n        \n        x = self.input_conv(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        \n        x = self.attention_pool(x)\n        x = self.classifier(x)\n        \n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, device, \n                epochs=20, patience=5, lr=1e-3):\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_val_loss = float(\"inf\")\n    patience_counter = 0\n    \n    history = {\"train_loss\": [], \"val_loss\": [], \n               \"val_acc\": [], \"val_precision\": [], \"val_recall\": [], \"val_f1\": []}\n\n    for epoch in range(epochs):\n        # Training\n        model.train()\n        running_loss = 0.0\n        for mel_batch, labels in train_loader:\n            mel_batch, labels = mel_batch.to(device), labels.to(device)\n\n            outputs = model(mel_batch)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * mel_batch.size(0)\n\n        train_loss = running_loss / len(train_loader.dataset)\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        all_preds, all_labels = [], []\n        all_probs = []\n\n        with torch.no_grad():\n            for mel_batch, labels in val_loader:\n                mel_batch, labels = mel_batch.to(device), labels.to(device)\n        \n                outputs = model(mel_batch)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * mel_batch.size(0)\n        \n                probs = torch.softmax(outputs, dim=1)[:,1].cpu().numpy()  # proba classe \"spoof\"\n                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n        \n                all_probs.extend(probs)\n                all_preds.extend(preds)\n                all_labels.extend(labels.cpu().numpy())\n        \n        plot_confusion_matrix(all_labels, all_preds)\n        plot_calibration_curve(all_labels, all_probs)\n        \n        val_loss /= len(val_loader.dataset)\n        acc = accuracy_score(all_labels, all_preds)\n        precision, recall, f1, _ = precision_recall_fscore_support(\n            all_labels, all_preds, average=\"binary\", zero_division=0\n        )\n\n        # Logging\n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss)\n        history[\"val_acc\"].append(acc)\n        history[\"val_precision\"].append(precision)\n        history[\"val_recall\"].append(recall)\n        history[\"val_f1\"].append(f1)\n\n        print(f\"Epoch {epoch+1}/{epochs} | \"\n              f\"Train Loss: {train_loss:.4f} | \"\n              f\"Val Loss: {val_loss:.4f} | \"\n              f\"Acc: {acc:.4f} | \"\n              f\"Prec: {precision:.4f} | \"\n              f\"Rec: {recall:.4f} | \"\n              f\"F1: {f1:.4f}\")\n\n        # Early Stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), \"best_model.pth\")\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(\"Early stopping triggered!\")\n                break\n\n    print(\"Training finished. Best model saved as best_model.pth\")\n    return history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, labels=[0,1], class_names=[\"bonafide\",\"spoof\"]):\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_calibration_curve(y_true, y_probs, n_bins=10):\n    prob_true, prob_pred = calibration_curve(y_true, y_probs, n_bins=n_bins)\n\n    plt.figure(figsize=(6,6))\n    plt.plot(prob_pred, prob_true, marker='o', label=\"Model calibration\")\n    plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\", label=\"Perfectly calibrated\")\n    plt.xlabel(\"Mean predicted probability\")\n    plt.ylabel(\"Fraction of positives\")\n    plt.title(\"Calibration Curve (Reliability Diagram)\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_MFCC = 39\nmodel = SpoofNet(input_features=N_MELS + N_MFCC + 60).to(device)\nhistory = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    device=device,\n    epochs=EPOCH,\n    patience=PATIENCE,\n    lr=1e-3\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"print(\"Loading best model...\")\nbest_model.load_state_dict(torch.load(\"best_model.pth\"))\nprint(\"Best model loaded successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_SAMPLE_TEST=4000","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"la_test = read_proto_file(PROTO_FILE_TEST_LA, AUDIO_DIR_TEST_LA, \"flac\", \"LA\")\nla_t_1 = la_test[la_test[\"label\"] == 1].sample(n=N_SAMPLE_TEST//2, random_state=RANDOM_STATE)\nla_t_0 = la_test[la_test[\"label\"] == 0].sample(n=N_SAMPLE_TEST//2, random_state=RANDOM_STATE)\nla_test_reduced = pd.concat([la_t_1, la_t_0], ignore_index=True)\npa_test = read_proto_file(PROTO_FILE_TEST_PA, AUDIO_DIR_TEST_PA, \"flac\", \"PA\")\npa_t_1 = pa_test[pa_test[\"label\"] == 1].sample(n=N_SAMPLE_TEST//2, random_state=RANDOM_STATE)\npa_t_0 = pa_test[pa_test[\"label\"] == 0].sample(n=N_SAMPLE_TEST//2, random_state=RANDOM_STATE)\npa_test_reduced = pd.concat([pa_t_1, pa_t_0], ignore_index=True)\ntest_df = pd.concat([la_test_reduced, pa_test_reduced], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_mel(\n    df=test_df, \n    output_path=\"mel_test\", \n    augmentation=False,\n    probability_of_augment=0.0\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = SpoofDataset(test_df, \"mel_test\")\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, \n                        num_workers=4, pin_memory=True, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_eer(y_true, y_scores):\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n    fnr = 1 - tpr\n    eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n\n    return eer * 100, eer_threshold","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_score_distribution(y_true, y_scores, title=\"Score Distribution\"):\n    \"\"\"Plot score distribution for bonafide vs spoof\"\"\"\n    bonafide_scores = y_scores[y_true == 0]\n    spoof_scores = y_scores[y_true == 1]\n\n    plt.figure(figsize=(10, 6))\n    plt.hist(bonafide_scores, bins=50, alpha=0.7, label='Bonafide', color='blue', density=True)\n    plt.hist(spoof_scores, bins=50, alpha=0.7, label='Spoof', color='red', density=True)\n    plt.xlabel('Prediction Score')\n    plt.ylabel('Density')\n    plt.title(title)\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def comprehensive_evaluation(model, test_loader, device, dataset_name=\"Test\"):\n    \"\"\"Comprehensive evaluation pipeline\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []\n    total_loss = 0.0\n    criterion = nn.CrossEntropyLoss()\n    \n    print(f\"Evaluating on {dataset_name} set...\")\n    \n    with torch.no_grad():\n        for mel_batch, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            mel_batch, labels = mel_batch.to(device), labels.to(device)\n            \n            outputs = model(mel_batch)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item() * mel_batch.size(0)\n            \n            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            \n            all_probs.extend(probs)\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n    \n    all_labels = np.array(all_labels)\n    all_preds = np.array(all_preds)\n    all_probs = np.array(all_probs)\n    \n    avg_loss = total_loss / len(test_loader.dataset)\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, average='binary')\n    recall = recall_score(all_labels, all_preds, average='binary')\n    f1 = f1_score(all_labels, all_preds, average='binary')\n    auc = roc_auc_score(all_labels, all_probs)\n    eer, eer_threshold = calculate_eer(all_labels, all_probs)\n    \n    print(f\"\\n{dataset_name} Set Evaluation Results:\")\n    print(\"=\"*50)\n    print(f\"Loss: {avg_loss:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"AUC-ROC: {auc:.4f}\")\n    print(f\"EER: {eer:.2f}%\")\n    print(f\"EER Threshold: {eer_threshold:.4f}\")\n    print(\"=\"*50)\n    \n    plot_score_distribution(all_labels, all_probs, f\"{dataset_name} Set - Score Distribution\")\n\n    plt.figure(figsize=(8, 6))\n    cm = confusion_matrix(all_labels, all_preds)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=['Bonafide', 'Spoof'], \n                yticklabels=['Bonafide', 'Spoof'])\n    plt.title(f'{dataset_name} Set - Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n    \n    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc:.4f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'{dataset_name} Set - ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True, alpha=0.3)\n    plt.show()\n    \n    prob_true, prob_pred = calibration_curve(all_labels, all_probs, n_bins=10)\n    plt.figure(figsize=(8, 6))\n    plt.plot(prob_pred, prob_true, marker='o', linewidth=2, label='Model calibration')\n    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n    plt.xlabel('Mean Predicted Probability')\n    plt.ylabel('Fraction of Positives')\n    plt.title(f'{dataset_name} Set - Calibration Curve')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.show()\n    \n    from sklearn.metrics import precision_recall_curve, average_precision_score\n    precision_curve, recall_curve, _ = precision_recall_curve(all_labels, all_probs)\n    ap_score = average_precision_score(all_labels, all_probs)\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(recall_curve, precision_curve, color='blue', lw=2, \n             label=f'PR curve (AP = {ap_score:.4f})')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(f'{dataset_name} Set - Precision-Recall Curve')\n    plt.legend(loc=\"lower left\")\n    plt.grid(True, alpha=0.3)\n    plt.show()\n    \n    return {\n        'loss': avg_loss,\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc,\n        'eer': eer,\n        'eer_threshold': eer_threshold,\n        'predictions': all_preds,\n        'probabilities': all_probs,\n        'true_labels': all_labels\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_results = comprehensive_evaluation(best_model, test_loader, device, \"Test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}